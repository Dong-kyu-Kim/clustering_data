import pandas as pd
import hvplot.pandas
import matplotlib.pyplot as plt
from pathlib import Path
from sklearn import metrics
from sklearn.cluster import KMeans, AgglomerativeClustering, Birch
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA


# Load the dataset
# Set "Date" column to the index
import warnings

warnings.filterwarnings("ignore")

stock_df = pd.read_csv(
    Path("./resources/stock_market.csv")
)

stock_df


# Check the dataset whether clean or not
stock_df.info()


# Remmove "$" and change the "Close/Last", "Open", "High", and "Low" columns data type to the float
stock_df["Close/Last"] = stock_df["Close/Last"].str.replace("$", "").astype(float)
stock_df["Open"] = stock_df["Open"].str.replace("$", "").astype(float)
stock_df["High"] = stock_df["High"].str.replace("$", "").astype(float)
stock_df["Low"] = stock_df["Low"].str.replace("$", "").astype(float)

stock_df


# Check the dataset
stock_df.info()


# Add new columns
stock_df["close_to_open(%)"] = (stock_df["Close/Last"] / stock_df["Open"]) * 100
stock_df["high_to_low(%)"] = (stock_df["High"] / stock_df["Low"]) * 100
stock_df['high_to_close(%)'] = (stock_df['High'] / stock_df['Close/Last']) * 100

stock_df


# Normalize the data, scaling selected columns to a mean of 0 and a standard deviation of 1 
stock_df_scaled = StandardScaler().fit_transform(stock_df[["Volume", "close_to_open(%)", "high_to_low(%)", "high_to_close(%)"]])

stock_df_scaled = pd.DataFrame(data = stock_df_scaled, 
                               columns = ["Volume", "close_to_open(%)", "high_to_low(%)", "high_to_close(%)"], 
                               index = stock_df.index)

stock_df_scaled


# Reduce the dimensionality of the data using PCA (Principal Component Analysis)
pca = PCA(n_components = 2)
pca_reduced = pca.fit_transform(stock_df_scaled)
pca_reduced_df = pd.DataFrame(data = pca_reduced, columns = ["PCA_1", "PCA_2"])
pca_reduced_df


# 80% of the data variance can be explained by two principal components.
sum(pca.explained_variance_ratio_)


# Elbow method is used to find the optimal number of clusters by plotting the inertia for different k values
inertia = []
k = list(range(1, 21))

for i in k:
    k_model = KMeans(n_clusters = i, random_state = 1)
    k_model.fit(pca_reduced_df)
    inertia.append(k_model.inertia_)

elbow_df = {
    "k": k,
    "inertia": inertia
}

elbow_df = pd.DataFrame(data = elbow_df)

elbow_df.hvplot.line(
    x = "k",
    y = "inertia",
    color = 'red',
    alpha = 0.6
)


# We cannot explicitly know which point is the best cluster point.
# So, use calinski harabasz score to figure out which number is the best cluster number
scores = []
k = list(range(2, 21))

for i in k:
    k_model = KMeans(n_clusters = i, random_state = 1)
    k_model.fit(pca_reduced_df)
    labels = k_model.labels_
    score = metrics.calinski_harabasz_score(pca_reduced_df, labels)
    scores.append(score)

ch_score_df = pd.DataFrame(data = scores, 
                           columns = ["calinski_harabasz_score"], 
                           index = k)

ch_score_df


print(ch_score_df.max())
print("The best cluster number seems 4.")


# Training the model with 4 clusters
k_model = KMeans(n_clusters = 4, random_state = 1)
k_model.fit(pca_reduced_df)
cluster_segment = k_model.predict(pca_reduced_df)
cluster_segment


# Copy a dataframe and add cluster segment to the dataframe
stock_clusters_df = pca_reduced_df.copy()
stock_clusters_df["cluster_segment"] = cluster_segment
stock_clusters_df


# Visualize clustered data
stock_clusters_df.hvplot.scatter(
    x = "PCA_1",
    y = "PCA_2",
    by = "cluster_segment",
    marker = 'x',
    alpha = 0.7
)


# Add the cluster segement column to the data before PCA
stock_df_before_pca = pd.DataFrame(data = stock_df, 
                              columns = ["Volume", "close_to_open(%)", "high_to_low(%)", "high_to_close(%)"], 
                              index = stock_df.index)

stock_df_before_pca_clustered = pd.concat([stock_df_before_pca, stock_clusters_df["cluster_segment"]], axis = 1)
stock_df_before_pca_clustered



